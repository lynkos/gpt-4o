<div align="center">
<h1>LLM Stuff</h1>
<img alt="Python" src="https://img.shields.io/static/v1?label=Language&style=flat&message=Python+3.12.7&logo=python&color=c7a228&labelColor=393939&logoColor=4f97d1">
<img alt="Shell" src="https://img.shields.io/static/v1?label=Shell&style=flat&message=Bash&logo=gnu+bash&color=4EAA25&labelColor=393939&logoColor=4EAA25">
<img alt="Code Editor" src="https://img.shields.io/static/v1?label=Code+Editor&style=flat&message=Visual+Studio+Code&color=007acc&labelColor=393939">
<br>
<a href="https://platform.openai.com/docs/models/gpt-4o" alt="Documentation for OpenAI GPT-4o" target="_blank"><img alt="OpenAI GPT-4o" src="https://img.shields.io/static/v1?label=Models&style=flat&message=OpenAI+GPT-4o&logo=openai&color=0ea882&labelColor=393939&logoColor=0ea882"></a>
<a href="https://www.llama.com" target="_blank" alt="Website for Meta Llama 3.2"><img alt="Meta Llama 3.2" src="https://img.shields.io/static/v1?label=Models&style=flat&message=Meta+Llama 3.2&logo=meta&color=0467DF&labelColor=393939&logoColor=0467DF"></a>
<a href="https://cohere.com/blog/introducing-embed-v3" target="_blank" alt="Blogpost about Cohere Embed V3"><img alt="Cohere Embed V3" src="https://img.shields.io/static/v1?label=Models&style=flat&message=Cohere+Embed+V3&logo=data:image/svg+xml;base64,PHN2ZyB2ZXJzaW9uPSIxLjEiIGlkPSJMYXllcl8xIiB4bWxuczp4PSJuc19leHRlbmQ7IiB4bWxuczppPSJuc19haTsiIHhtbG5zOmdyYXBoPSJuc19ncmFwaHM7IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB4PSIwcHgiIHk9IjBweCIgdmlld0JveD0iMCAwIDc1IDc1IiBzdHlsZT0iZW5hYmxlLWJhY2tncm91bmQ6bmV3IDAgMCA3NSA3NTsiIHhtbDpzcGFjZT0icHJlc2VydmUiPgogPHN0eWxlIHR5cGU9InRleHQvY3NzIj4KICAuc3Qwe2ZpbGwtcnVsZTpldmVub2RkO2NsaXAtcnVsZTpldmVub2RkO2ZpbGw6IzM5NTk0RDt9Cgkuc3Qxe2ZpbGwtcnVsZTpldmVub2RkO2NsaXAtcnVsZTpldmVub2RkO2ZpbGw6I0QxOEVFMjt9Cgkuc3Qye2ZpbGw6I0ZGNzc1OTt9CiA8L3N0eWxlPgogPG1ldGFkYXRhPgogIDxzZncgeG1sbnM9Im5zX3NmdzsiPgogICA8c2xpY2VzPgogICA8L3NsaWNlcz4KICAgPHNsaWNlU291cmNlQm91bmRzIGJvdHRvbUxlZnRPcmlnaW49InRydWUiIGhlaWdodD0iNzUiIHdpZHRoPSI3NSIgeD0iLTM0Ny42IiB5PSIwLjUiPgogICA8L3NsaWNlU291cmNlQm91bmRzPgogIDwvc2Z3PgogPC9tZXRhZGF0YT4KIDxnPgogIDxnPgogICA8Zz4KICAgIDxwYXRoIGNsYXNzPSJzdDAiIGQ9Ik0yNC4zLDQ0LjdjMiwwLDYtMC4xLDExLjYtMi40YzYuNS0yLjcsMTkuMy03LjUsMjguNi0xMi41YzYuNS0zLjUsOS4zLTguMSw5LjMtMTQuM0M3My44LDcsNjYuOSwwLDU4LjMsMAoJCQkJaC0zNkMxMCwwLDAsMTAsMCwyMi4zUzkuNCw0NC43LDI0LjMsNDQuN3oiPgogICAgPC9wYXRoPgogICAgPHBhdGggY2xhc3M9InN0MSIgZD0iTTMwLjQsNjBjMC02LDMuNi0xMS41LDkuMi0xMy44bDExLjMtNC43QzYyLjQsMzYuOCw3NSw0NS4yLDc1LDU3LjZDNzUsNjcuMiw2Ny4yLDc1LDU3LjYsNzVsLTEyLjMsMAoJCQkJQzM3LjEsNzUsMzAuNCw2OC4zLDMwLjQsNjB6Ij4KICAgIDwvcGF0aD4KICAgIDxwYXRoIGNsYXNzPSJzdDIiIGQ9Ik0xMi45LDQ3LjZMMTIuOSw0Ny42QzUuOCw0Ny42LDAsNTMuNCwwLDYwLjV2MS43QzAsNjkuMiw1LjgsNzUsMTIuOSw3NWgwYzcuMSwwLDEyLjktNS44LDEyLjktMTIuOXYtMS43CgkJCQlDMjUuNyw1My40LDIwLDQ3LjYsMTIuOSw0Ny42eiI+CiAgICA8L3BhdGg+CiAgIDwvZz4KICA8L2c+CiA8L2c+Cjwvc3ZnPg==&color=fc745c&labelColor=393939"> <!-- Alt color: #d48ee3 --></a>
</div><br>

Hodgepodge of experiments, tests, etc. with several Large Language Models (LLMs), courtesy of [GitHub Models](https://docs.github.com/en/github-models).

Current models:
- [OpenAI GPT-4o](src/OpenAI/GPT-4o.py)
- [Meta Llama 3.2 (90B parameters)](src/Meta/Llama3_2.py)
- [Cohere Embed V3](src/Cohere/EmbedV3.py)

Refer to the [TODO](#todo) section for a list of models I plan to add.

TL;DR LLM playground

## Requirements
- [x] [Anaconda](https://docs.continuum.io/free/anaconda/install) **OR** [Miniconda](https://docs.conda.io/projects/miniconda/en/latest)

> [!TIP]
> If you have trouble deciding between Anaconda and Miniconda, please refer to the table below
> <table>
>  <thead>
>   <tr>
>    <th><center>Anaconda</center></th>
>    <th><center>Miniconda</center></th>
>   </tr>
>  </thead>
>  <tbody>
>   <tr>
>    <td>New to conda and/or Python</td>
>    <td>Familiar with conda and/or Python</td>
>   </tr>
>   <tr>
>    <td>Not familiar with using terminal and prefer GUI</td>
>    <td>Comfortable using terminal</td>
>   </tr>
>   <tr>
>    <td>Like the convenience of having Python and 1,500+ scientific packages automatically installed at once</td>
>    <td>Want fast access to Python and the conda commands and plan to sort out the other programs later</td>
>   </tr>
>   <tr>
>    <td>Have the time and space (a few minutes and 3 GB)</td>
>    <td>Don't have the time or space to install 1,500+ packages</td>
>   </tr>
>   <tr>
>    <td>Don't want to individually install each package</td>
>    <td>Don't mind individually installing each package</td>
>   </tr>
>  </tbody>
> </table>
>
> Typing out entire Conda commands can sometimes be tedious, so I wrote a shell script ([`conda_shortcuts.sh` on GitHub Gist](https://gist.github.com/lynkos/7a4ce7f9e38bb56174360648461a3dc8)) to define shortcuts for commonly used Conda commands.
> <details>
>   <summary>Example: Delete/remove a conda environment named <code>test_env</code></summary>
>
> * Shortcut command
>     ```
>     rmenv test_env
>     ```
> * Manually typing out the entire command
>     ```sh
>     conda env remove -n test_env && rm -rf $(conda info --base)/envs/test_env
>     ```
>
> The shortcut has 80.8% less characters!
> </details>

## Installation
1. Verify that conda is installed
   ```
   conda --version
   ```
2. Ensure conda is up to date
   ```
   conda update conda
   ```
3. Enter the directory where you want the repository ([`llm-stuff`](https://github.com/lynkos/llm-stuff)) to be cloned
     * POSIX
       ```sh
       cd ~/path/to/directory
       ```
     * Windows
       ```sh
       cd C:\path\to\directory
       ```
4. Clone the repository ([`llm-stuff`](https://github.com/lynkos/llm-stuff)), then enter (i.e. `cd` command) `llm-stuff` directory
   ```sh
   git clone https://github.com/lynkos/llm-stuff.git && cd llm-stuff
   ```
5. Create a conda virtual environment from [`environment.yml`](environment.yml)
   ```
   conda env create -f environment.yml
   ```
6. Activate the virtual environment (`llm_env`)
   ```
   conda activate llm_env
   ```
7. Confirm that the virtual environment (`llm_env`) is active
     * If active, the virtual environment's name should be in parentheses () or brackets [] before your command prompt, e.g.
       ```
       (llm_env) $
       ```
     * If necessary, see which environments are available and/or currently active (active environment denoted with asterisk (*))
       ```
       conda info --envs
       ```
       **OR**
       ```
       conda env list
       ```

## Usage
Depending on the LLM you want to use, execute any of the following commands in your preferred Terminal.

### OpenAI GPT-4o
```sh
python -m src.OpenAI.GPT-4o
```

### Meta Llama 3.2 (90B)
```sh
python -m src.Meta.Llama3_2
```

### Cohere Embed V3
```sh
python -m src.Cohere.EmbedV3
```

## TODO
- [ ] Add more [models](https://github.com/marketplace/models)
  - [ ] [Meta Llama 3.1 Instruct (405B)](https://www.llama.com)
  - [ ] [Microsoft Phi 3.5 MoE Instruct (128k)](https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/discover-the-new-multi-lingual-high-quality-phi-3-5-slms/ba-p/4225280)
  - [ ] [Microsoft Phi 3.5 Vision Instruct (128k)](https://techcommunity.microsoft.com/t5/educator-developer-blog/a-better-phi-family-is-coming-multi-language-support-better/ba-p/4224181)
  - [ ] [Cohere Embed V3 English](https://cohere.com/blog/introducing-embed-v3)
  - [ ] [Mistral Nemo](https://mistral.ai/news/mistral-nemo)
  - [ ] [AI21 Jamba 1.5 Large](https://www.ai21.com/jamba)
- [ ] Add command line functionality
- [ ] Separate classes for vision and language models
- [ ] Logging for debugging
- [ ] Save convo transcript option